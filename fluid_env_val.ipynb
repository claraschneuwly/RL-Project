{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluid Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FluidMechanicsEnv:\n",
    "    \n",
    "    class Wave:\n",
    "        def __init__(self, a, T, k) :\n",
    "            self.a = a                  # Wave amplitude\n",
    "            self.T = T                  # Wave period\n",
    "            self.omega = 2 * np.pi / T  # Wave frequency\n",
    "            self.k = .1   \n",
    "\n",
    "    class Wind:\n",
    "        def __init__(self, Ux, Uy, alpha, sigma) :\n",
    "            self.Ux = Ux                  # Wave amplitude\n",
    "            self.Uy = Uy                  # Wave period\n",
    "            self.alpha = alpha            # Wave frequency\n",
    "            self.sigma = sigma\n",
    "\n",
    "    def __init__(self, a, T, k,  Ux, Uy, alpha, sigma, x_goal, y_goal, pos0, theta0, dist_threshold=0.1, max_steps=1000):\n",
    "        self.t = 0\n",
    "        self.wave = self.Wave(a, T, k)\n",
    "        self.wind = self.Wind(Ux, Uy, alpha, sigma)\n",
    "        self.max_steps = max_steps\n",
    "        self.dist_threshold = dist_threshold\n",
    "        self.max_x, self.min_x = 100 , -100  # agent has drifted too far, admit defeat\n",
    "        self.max_y, self.min_y = 100 , -100 # agent has drifted too far, admit defeat\n",
    "        self.x_goal, self.y_goal, self.z_goal = x_goal, y_goal, 0 # coordinates of goal\n",
    "        self.done = False\n",
    "        self.goal_reached = False\n",
    "        self.steps_count = 0\n",
    "        self.sum_reward = 0\n",
    "        self.all_actions = []\n",
    "        self.pos = pos0\n",
    "        self.theta = theta0\n",
    "        self.vel = np.array([0, 0, 0]).astype(np.float32)\n",
    "        self.thrust = 0 # [0; 1]\n",
    "        self.rudder = 0.0 # [-pi/4; pi/4]\n",
    "        self.action = np.array([0, 0])\n",
    "        self.u_history = []\n",
    "        self.v_history = []\n",
    "\n",
    "        self.state_dim = 3  # x, y, z. Should add later u_swell, u_wind, v_wind, w_swell\n",
    "        self.action_dim = 2  # thrust, rudder angle\n",
    "\n",
    "    def water_surface_level(self, pos) :\n",
    "        x, _, _ = pos\n",
    "        eta = self.wave.a * np.sin(self.wave.omega * self.t - self.wave.k * x)\n",
    "        return eta\n",
    "\n",
    "    def water_speed(self, pos) :\n",
    "        x, y, z = pos\n",
    "        eta = self.water_surface_level(pos)\n",
    "\n",
    "        u_swell = self.wave.a * self.wave.omega * np.exp(self.wave.k * z) * np.sin(self.wave.omega * self.t - self.wave.k * x)\n",
    "        w_swell = self.wave.a * self.wave.omega * np.exp(self.wave.k * z) * np.cos(self.wave.omega * self.t - self.wave.k * x)\n",
    "        \n",
    "        u_wind = np.random.normal(self.wind.Ux, self.wind.sigma) * np.exp(-self.wind.alpha * (eta - z))\n",
    "        v_wind = np.random.normal(self.wind.Uy, self.wind.sigma) * np.exp(-self.wind.alpha * (eta - z))\n",
    "\n",
    "        # u = u + np.random.normal(0, noise, u.shape)\n",
    "        # v = v + np.random.normal(0, noise, v.shape)\n",
    "        # w = w + np.random.normal(0, noise, w.shape)\n",
    "\n",
    "        return u_swell + u_wind, v_wind, w_swell\n",
    "\n",
    "    def inertia(self, lag = 5) :\n",
    "\n",
    "        if len(self.u_history) > 0 :\n",
    "\n",
    "            k = np.minimum(lag, len(self.u_history))\n",
    "            coefs = np.array([1 / (4 ** (i + 1)) for i in reversed(range(k))])\n",
    "            u = (self.u_history[-k:] * coefs).sum() / coefs.sum()\n",
    "            v = (self.v_history[-k:] * coefs).sum() / coefs.sum()\n",
    "\n",
    "        else :\n",
    "            u, v = 0, 0\n",
    "\n",
    "        return np.array([u, v, 0])\n",
    "    \n",
    "    def update_pos(self, action):\n",
    "        # Sets agent action\n",
    "        self.thrust = action[0]\n",
    "        self.rudder = action[1]\n",
    "    \n",
    "        # Find the water velocity at agent position\n",
    "        x, y, z = self.pos\n",
    "        u, v, w = self.water_speed(self.pos)\n",
    "        self.vel = np.array([u, v, w])\n",
    "\n",
    "        # Add inertia to the agent's velocity\n",
    "        self.vel += self.inertia()\n",
    "\n",
    "        # Perform agent action\n",
    "        self.theta -= self.rudder # Update agent's orientation from rudder angle\n",
    "        u_action = self.thrust * np.sin(self.theta)\n",
    "        v_action = self.thrust * np.cos(self.theta)\n",
    "        self.vel += np.array([u_action, v_action, 0])\n",
    "\n",
    "        # Update velocity history\n",
    "        self.u_history.append(u)\n",
    "        self.v_history.append(v)\n",
    "\n",
    "        # Update agent position\n",
    "        x += self.vel[0]\n",
    "        y += self.vel[1]\n",
    "        z = self.water_surface_level((x, y, z))\n",
    "\n",
    "        return np.array([x, y, z])\n",
    "    \n",
    "    def get_reward(self):\n",
    "        \n",
    "        # Calculate euclidian dist to goal Without z coord\n",
    "        goal_pos = np.array([self.x_goal, self.y_goal])\n",
    "        dist_to_goal = np.linalg.norm(np.array(self.pos[:2]) - goal_pos)\n",
    "        reward = - dist_to_goal\n",
    "        if dist_to_goal <= self.dist_threshold:\n",
    "            reward += 10\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def success(self):\n",
    "        \"\"\"Returns True if x,y is near enough goal\"\"\"\n",
    "        goal_pos = np.array([self.x_goal, self.y_goal])\n",
    "        dist_to_goal = np.linalg.norm(np.array(self.pos[:2]) - goal_pos)\n",
    "        if  dist_to_goal <= self.dist_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def admit_defeat(self):\n",
    "        \"\"\"Returns True if the agent has drifted too far away from goal\"\"\"\n",
    "        if self.pos[0] > self.max_x or self.pos[0] < self.min_x or self.pos[1] > self.max_y or self.pos[1] < self.min_y:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def step(self, action) :\n",
    "        \n",
    "        self.pos = self.update_pos(action)\n",
    "        self.reward = self.get_reward()\n",
    "        self.sum_reward += self.reward\n",
    "        self.steps_count += 1\n",
    "        self.all_actions += [action]\n",
    "\n",
    "        if self.success():\n",
    "            self.done = True\n",
    "            self.goal_reached = True\n",
    "\n",
    "        elif self.admit_defeat() or self.steps_count > self.max_steps:\n",
    "            self.done = True\n",
    "\n",
    "        return self.pos, self.reward, self.sum_reward, self.done, self.steps_count, self.all_actions\n",
    "    \n",
    "    def reset(self):\n",
    "\n",
    "        self.rudder = 0\n",
    "        self.thrust = 0  \n",
    "        self.pos = np.array([0, 0, 0])\n",
    "        self.done = False\n",
    "        self.goal_reached = False\n",
    "        self.steps_count = 0\n",
    "        self.sum_reward = 0\n",
    "        \n",
    "        return self.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.70710678,  0.70710678, -0.        ]),\n",
       " -0.41421356237309503,\n",
       " -0.41421356237309503,\n",
       " False,\n",
       " 1,\n",
       " [array([ 1.        , -0.78539816])])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = FluidMechanicsEnv(a=0,\n",
    "                        T=1,\n",
    "                        k=0.1,\n",
    "                        Ux=0,\n",
    "                        Uy=0,\n",
    "                        alpha=1, \n",
    "                        sigma=0, \n",
    "                        x_goal=1,\n",
    "                        y_goal=1, \n",
    "                        pos0=np.array([0, 0, 0]), \n",
    "                        theta0=0, \n",
    "                        dist_threshold=0.1, \n",
    "                        max_steps=1000)\n",
    "\n",
    "action = np.array([1, -np.pi/4])\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.98994949,  0.98994949, -0.        ]),\n",
       " 9.985786437626905,\n",
       " 9.571572875253809,\n",
       " True,\n",
       " 2,\n",
       " [array([ 1.        , -0.78539816]), array([0.4, 0. ])])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = np.array([.4, 0])\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "class ACModel(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_size=64):\n",
    "        super(ACModel, self).__init__()\n",
    "        # Common hidden layer\n",
    "        self.common = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Actor - Output parameters for the distributions\n",
    "        self.actor_thrust = nn.Linear(hidden_size, 2)  # Parameters for Beta distribution (alpha, beta)\n",
    "        self.actor_rudder = nn.Linear(hidden_size, 2)  # Parameters for Gaussian distribution (mean, std_dev)\n",
    "        # Critic\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.common(state)\n",
    "        # Thrust\n",
    "        thrust_params = torch.exp(self.actor_thrust(x))  # Ensure parameters are positive\n",
    "        thrust_dist = dist.Beta(thrust_params[:, 0]+1, thrust_params[:, 1]+1)  # Adding 1 to avoid 0\n",
    "        # Rudder\n",
    "        rudder_params = torch.exp(self.actor_rudder(x))\n",
    "        rudder_dist = dist.Beta(rudder_params[:, 0]+1, rudder_params[:, 1]+1)\n",
    "\n",
    "        # Compute value\n",
    "        value = self.critic(state)\n",
    "        return thrust_dist, self.rescale_beta(rudder_dist, -np.pi/4, np.pi/4), value\n",
    "\n",
    "    def rescale_beta(self, beta_dist, low, high):\n",
    "        \"\"\"\n",
    "        Rescale a Beta distribution to a new interval [low, high].\n",
    "        \"\"\"\n",
    "        def sample_rescaled(*args, **kwargs):\n",
    "            samples = beta_dist.sample(*args, **kwargs)\n",
    "            return low + (high - low) * samples\n",
    "\n",
    "        def log_prob_rescaled(samples):\n",
    "            # Adjust samples to original Beta scale\n",
    "            original_samples = (samples - low) / (high - low)\n",
    "            # Compute log_prob on the original scale, adjust for the scale transformation\n",
    "            return beta_dist.log_prob(original_samples) - torch.log(torch.tensor(high - low))\n",
    "        def entropy_rescaled():\n",
    "            scale = high - low\n",
    "            return beta_dist.entropy() + torch.log(torch.tensor(scale, dtype=torch.float))\n",
    "\n",
    "        # Return a simple object with adjusted sample, log_prob, and entropy methods\n",
    "        return type('RescaledBeta', (object,), {\n",
    "            'sample': sample_rescaled,\n",
    "            'log_prob': log_prob_rescaled,\n",
    "            'entropy': entropy_rescaled\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self,\n",
    "                score_threshold=0.93,\n",
    "                discount=0.995,\n",
    "                lr=1e-3,\n",
    "                max_grad_norm=0.5,\n",
    "                log_interval=10,\n",
    "                max_episodes=500,\n",
    "                gae_lambda=0.95,\n",
    "                use_critic=False,\n",
    "                clip_ratio=0.2,\n",
    "                target_kl=0.01,\n",
    "                train_ac_iters=5,\n",
    "                use_discounted_reward=False,\n",
    "                entropy_coef=0.01,\n",
    "                use_gae=False):\n",
    "\n",
    "        self.score_threshold = score_threshold # criterion for early stopping. If the rolling average reward (over the last 100 episodes) is greater than it, it ends.\n",
    "        self.discount = discount # discount factor\n",
    "        self.lr = lr # learning rate\n",
    "        self.max_grad_norm = max_grad_norm # the maximum gradient norm (https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
    "        self.log_interval = log_interval # logging interval\n",
    "        self.max_episodes = max_episodes # the maximum number of episodes.\n",
    "        self.use_critic = use_critic # whether to use critic or not.\n",
    "        self.clip_ratio = clip_ratio # clip_ratio of PPO.\n",
    "        self.target_kl = target_kl # target KL divergence for early stoping train_ac_iters for PPO\n",
    "        self.train_ac_iters = train_ac_iters # how many time to train ac_model using current computed old_logps\n",
    "        self.gae_lambda=gae_lambda # lambda in Generalized Advantage Estimation (GAE)\n",
    "        self.use_discounted_reward=use_discounted_reward # whether use discounted reward or not.\n",
    "        self.entropy_coef = entropy_coef # entropy coefficient for PPO\n",
    "        self.use_gae = use_gae # whether to use GAE or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discounted_return(rewards, discount, device=None):\n",
    "    \"\"\"\n",
    "\t\trewards: reward obtained at timestep.  Shape: (T,)\n",
    "\t\tdiscount: discount factor. float\n",
    "\n",
    "    ----\n",
    "    returns: sum of discounted rewards. Shape: (T,)\n",
    "\t\t\"\"\"\n",
    "    returns = torch.zeros(*rewards.shape, device=device)\n",
    "\n",
    "    R = 0\n",
    "    for t in reversed(range((rewards.shape[0]))):\n",
    "        R = rewards[t] + discount * R\n",
    "        returns[t] = R\n",
    "    return returns\n",
    "\n",
    "def compute_advantage_gae(values, rewards, T, gae_lambda, discount):\n",
    "    \"\"\"\n",
    "    Compute Adavantage wiht GAE. See Section 4.4.2 in the lecture notes.\n",
    "\n",
    "    values: value at each timestep (T,)\n",
    "    rewards: reward obtained at each timestep.  Shape: (T,)\n",
    "    T: the number of frames, float\n",
    "    gae_lambda: hyperparameter, float\n",
    "    discount: discount factor, float\n",
    "\n",
    "    -----\n",
    "\n",
    "    returns:\n",
    "\n",
    "    advantages : tensor.float. Shape [T,]\n",
    "\n",
    "                 gae advantage term for timesteps 0 to T\n",
    "\n",
    "    \"\"\"\n",
    "    advantages = torch.zeros_like(values)\n",
    "    for i in reversed(range(T)):\n",
    "        next_value = values[i+1]\n",
    "        next_advantage = advantages[i+1]\n",
    "\n",
    "        delta = rewards[i] + discount * next_value  - values[i]\n",
    "        advantages[i] = delta + discount * gae_lambda * next_advantage\n",
    "    return advantages[:T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_experiences(env, acmodel, args, device=None):\n",
    "    \"\"\"Collects rollouts and computes advantages.\n",
    "    Returns\n",
    "    -------\n",
    "    exps : dict\n",
    "        Contains actions, rewards, advantages etc as attributes.\n",
    "        Each attribute, e.g. `exps['reward']` has a shape\n",
    "        (self.num_frames, ...).\n",
    "    logs : dict\n",
    "        Useful stats about the training process, including the average\n",
    "        reward, policy loss, value loss, etc.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    MAX_FRAMES_PER_EP = 300\n",
    "    shape = (MAX_FRAMES_PER_EP, )\n",
    "\n",
    "    actions = torch.zeros((MAX_FRAMES_PER_EP, 2), device=device, dtype=torch.int)\n",
    "    values = torch.zeros(*shape, device=device)\n",
    "    rewards = torch.zeros(*shape, device=device)\n",
    "    log_probs = torch.zeros(*shape, device=device)\n",
    "    #obss = [None]*MAX_FRAMES_PER_EP\n",
    "    obss = torch.zeros((MAX_FRAMES_PER_EP, 3), device=device)\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    total_return = 0\n",
    "\n",
    "    T = 0\n",
    "\n",
    "    while True:\n",
    "        # Do one agent-environment interaction\n",
    "\n",
    "        with torch.no_grad():\n",
    "            obs = torch.from_numpy(obs).float()\n",
    "            obs = obs.unsqueeze(0)\n",
    "            thrust_dist, rudder_dist, value = acmodel(obs)\n",
    "        action = torch.stack((thrust_dist.sample(), rudder_dist.sample()), dim=-1).squeeze()\n",
    "        #print(action)\n",
    "        obss[T] = obs\n",
    "        obs, reward,  _, done, _, _ = env.step(action)\n",
    "\n",
    "        # Update experiences values\n",
    "        actions[T] = action\n",
    "        values[T] = value\n",
    "        rewards[T] = reward\n",
    "        print(thrust_dist.log_prob(action[0]) + rudder_dist.log_prob(action[1]))\n",
    "        log_probs[T] = thrust_dist.log_prob(action[0]) + rudder_dist.log_prob(action[1])\n",
    "\n",
    "        total_return += reward\n",
    "        T += 1\n",
    "\n",
    "        if done or T>=MAX_FRAMES_PER_EP-1:\n",
    "            break\n",
    "\n",
    "    discounted_reward = compute_discounted_return(rewards[:T], args.discount, device)\n",
    "    exps = dict(\n",
    "        obs = obss[:T],\n",
    "        action = actions[:T],\n",
    "        value  = values[:T],\n",
    "        reward = rewards[:T],\n",
    "        advantage = discounted_reward-values[:T],\n",
    "        log_prob = log_probs[:T],\n",
    "        discounted_reward = discounted_reward,\n",
    "        advantage_gae=compute_advantage_gae(values, rewards, T, args.gae_lambda, args.discount)\n",
    "    )\n",
    "\n",
    "    logs = {\n",
    "        \"return_per_episode\": total_return,\n",
    "        \"num_frames\": T\n",
    "    }\n",
    "\n",
    "    return exps, logs\n",
    "\n",
    "def run_experiment(args, parameter_update, env_param, seed=0):\n",
    "    \"\"\"\n",
    "    Upper level function for running experiments to analyze reinforce and\n",
    "    policy gradient methods. Instantiates a model, collects epxeriences, and\n",
    "    then updates the neccessary parameters.\n",
    "\n",
    "    args: Config arguments. dict\n",
    "    paramter_update: function used to update model parameters\n",
    "    seed: random seed. int\n",
    "\n",
    "    return: DataFrame indexed by episode\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    env = FluidMechanicsEnv(**env_param)\n",
    "\n",
    "    acmodel = ACModel(env.state_dim)\n",
    "    acmodel.to(device)\n",
    "\n",
    "    is_solved = False\n",
    "\n",
    "    SMOOTH_REWARD_WINDOW = 50\n",
    "\n",
    "    pd_logs, rewards = [], [0]*SMOOTH_REWARD_WINDOW\n",
    "\n",
    "    optimizer = torch.optim.Adam(acmodel.parameters(), lr=args.lr)\n",
    "    num_frames = 0\n",
    "\n",
    "    pbar = tqdm(range(args.max_episodes))\n",
    "    for update in pbar:\n",
    "        exps, logs1 = collect_experiences(env, acmodel, args, device)\n",
    "        logs2 = parameter_update(optimizer, acmodel, exps, args)\n",
    "\n",
    "        logs = {**logs1, **logs2}\n",
    "\n",
    "        num_frames += logs[\"num_frames\"]\n",
    "\n",
    "        rewards.append(logs[\"return_per_episode\"])\n",
    "\n",
    "        smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
    "\n",
    "        data = {'episode':update, 'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
    "                'reward':logs[\"return_per_episode\"], 'policy_loss':logs[\"policy_loss\"]}\n",
    "\n",
    "        if args.use_critic:\n",
    "            data['value_loss'] = logs[\"value_loss\"]\n",
    "\n",
    "        pd_logs.append(data)\n",
    "\n",
    "        pbar.set_postfix(data)\n",
    "\n",
    "        # Early terminate\n",
    "        if smooth_reward >= args.score_threshold:\n",
    "            is_solved = True\n",
    "            break\n",
    "\n",
    "    if is_solved:\n",
    "        print('Solved!')\n",
    "\n",
    "    return pd.DataFrame(pd_logs).set_index('episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_ppo(optimizer, acmodel, sb, args):\n",
    "    def _compute_policy_loss_ppo(obs, old_logp, actions, advantages):\n",
    "        '''\n",
    "        Computes the policy loss for PPO.\n",
    "\n",
    "        obs: observeration to pass into acmodel. shape: (T,)\n",
    "        old_logp: log probabilities from previous timestep. shape: (T,)\n",
    "        actions: action at this timestep. shape: (T,ImWidth,ImHeight,Channels)\n",
    "        advantages: the computed advantages. shape: (T,)\n",
    "\n",
    "        ---\n",
    "        returns\n",
    "\n",
    "        policy_loss : ppo policy loss as shown in line 6 of PPO alg. tensor.float. Shape (,1)\n",
    "        approx_kl: an appoximation of the kl_divergence. tensor.float. Shape (,1)\n",
    "        '''\n",
    "        policy_loss, approx_kl = 0, 0\n",
    "\n",
    "        ### TODO: implement PPO policy loss computation (30 pts).  #######\n",
    "\n",
    "        # Policy loss\n",
    "        T = len(obs)\n",
    "        eps = args.clip_ratio\n",
    "        thrust_dist, rudder_dist, _ = acmodel(obs)\n",
    "        print(actions)\n",
    "        #print(thrust_dist.log_prob(actions[:,0]))\n",
    "        logp = thrust_dist.log_prob(actions[:,0]) + rudder_dist.log_prob(actions[:,1])\n",
    "        #print(actions)\n",
    "        #print(logp)\n",
    "\n",
    "        for t in range(T):\n",
    "            if advantages[t] >= 0:\n",
    "              g = (1+eps)*advantages[t]\n",
    "            else:\n",
    "              g = (1-eps)*advantages[t]\n",
    "\n",
    "            policy_loss -= torch.min(g, logp[t].exp()/old_logp[t].exp()*advantages[t])\n",
    "\n",
    "        # Add entropy\n",
    "        entropy = thrust_dist.entropy() + rudder_dist.entropy() \n",
    "        policy_loss -= args.entropy_coef*entropy.sum()\n",
    "\n",
    "        # Normlaize\n",
    "        policy_loss = policy_loss/T\n",
    "\n",
    "        # KL oldprobs / new probs\n",
    "        for t in range(T):\n",
    "          r = logp[t].exp()/old_logp[t].exp()\n",
    "          approx_kl += (r-1) - r.log()\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        return policy_loss, approx_kl\n",
    "\n",
    "    def _compute_value_loss(obs, returns):\n",
    "        ### TODO: implement PPO value loss computation (10 pts) ##########\n",
    "\n",
    "        _, _, values = acmodel(obs)\n",
    "        value_loss = F.mse_loss(values.squeeze(),returns)\n",
    "        ##################################################################\n",
    "\n",
    "        return value_loss\n",
    "\n",
    "    #print(sb['obs'])    \n",
    "    thrust_dist, rudder_dist, _ = acmodel(sb['obs'])\n",
    "    old_logp = thrust_dist.log_prob(sb['action'][:,0]).detach() + rudder_dist.log_prob(sb['action'][:,1]).detach()\n",
    "\n",
    "    advantage = sb['advantage_gae'] if args.use_gae else sb['advantage']\n",
    "\n",
    "    policy_loss, _ = _compute_policy_loss_ppo(sb['obs'], old_logp, sb['action'], advantage)\n",
    "    value_loss = _compute_value_loss(sb['obs'], sb['discounted_reward'])\n",
    "\n",
    "    for i in range(args.train_ac_iters):\n",
    "        optimizer.zero_grad()\n",
    "        loss_pi, approx_kl = _compute_policy_loss_ppo(sb['obs'], old_logp, sb['action'], advantage)\n",
    "        loss_v = _compute_value_loss(sb['obs'], sb['discounted_reward'])\n",
    "\n",
    "        loss = loss_v + loss_pi\n",
    "        if approx_kl > 1.5 * args.target_kl:\n",
    "            break\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    update_policy_loss = policy_loss.item()\n",
    "    update_value_loss = value_loss.item()\n",
    "\n",
    "    logs = {\n",
    "        \"policy_loss\": update_policy_loss,\n",
    "        \"value_loss\": update_value_loss,\n",
    "    }\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_param = dict(\n",
    "    a=0,\n",
    "    T=1,\n",
    "    k=0.1,\n",
    "    Ux=0,\n",
    "    Uy=0,\n",
    "    alpha=1, \n",
    "    sigma=0, \n",
    "    x_goal=1,\n",
    "    y_goal=1, \n",
    "    pos0=np.array([0, 0, 0]), \n",
    "    theta0=0, \n",
    "    dist_threshold=0.1, \n",
    "    max_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bd306740884231b65c3ba92a693c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1116])\n",
      "tensor([-0.6643])\n",
      "tensor([-0.7115])\n",
      "tensor([-0.8853])\n",
      "tensor([-0.7300])\n",
      "tensor([-1.2273])\n",
      "tensor([0.1156])\n",
      "tensor([0.2306])\n",
      "tensor([0.3184])\n",
      "tensor([-0.0170])\n",
      "tensor([0.4551])\n",
      "tensor([-0.8843])\n",
      "tensor([-0.1896])\n",
      "tensor([0.4454])\n",
      "tensor([0.8957])\n",
      "tensor([0.8767])\n",
      "tensor([0.0395])\n",
      "tensor([0.3559])\n",
      "tensor([0.8894])\n",
      "tensor([-0.7751])\n",
      "tensor([0.6096])\n",
      "tensor([0.3332])\n",
      "tensor([0.8217])\n",
      "tensor([-0.3712])\n",
      "tensor([0.4599])\n",
      "tensor([0.4561])\n",
      "tensor([0.3522])\n",
      "tensor([1.2164])\n",
      "tensor([0.6940])\n",
      "tensor([0.9596])\n",
      "tensor([-1.2955])\n",
      "tensor([0.4747])\n",
      "tensor([0.2504])\n",
      "tensor([-0.9976])\n",
      "tensor([0.7084])\n",
      "tensor([-0.6149])\n",
      "tensor([0.6758])\n",
      "tensor([-0.1979])\n",
      "tensor([-0.3852])\n",
      "tensor([0.0487])\n",
      "tensor([-1.0933])\n",
      "tensor([0.6584])\n",
      "tensor([0.4218])\n",
      "tensor([0.7212])\n",
      "tensor([0.3952])\n",
      "tensor([0.4011])\n",
      "tensor([-0.2210])\n",
      "tensor([0.8262])\n",
      "tensor([0.0650])\n",
      "tensor([0.6106])\n",
      "tensor([0.3651])\n",
      "tensor([0.5908])\n",
      "tensor([0.6206])\n",
      "tensor([0.3323])\n",
      "tensor([0.4777])\n",
      "tensor([-0.8613])\n",
      "tensor([0.5189])\n",
      "tensor([0.4807])\n",
      "tensor([0.5975])\n",
      "tensor([-1.0619])\n",
      "tensor([0.0823])\n",
      "tensor([0.1864])\n",
      "tensor([-0.0637])\n",
      "tensor([-1.2304])\n",
      "tensor([0.1113])\n",
      "tensor([-0.3132])\n",
      "tensor([0.4516])\n",
      "tensor([-0.7103])\n",
      "tensor([0.5427])\n",
      "tensor([0.1635])\n",
      "tensor([0.0221])\n",
      "tensor([-0.7338])\n",
      "tensor([-0.5709])\n",
      "tensor([0.3525])\n",
      "tensor([0.3911])\n",
      "tensor([0.5575])\n",
      "tensor([0.4290])\n",
      "tensor([-1.1606])\n",
      "tensor([0.2816])\n",
      "tensor([0.2788])\n",
      "tensor([0.5363])\n",
      "tensor([0.5642])\n",
      "tensor([0.3162])\n",
      "tensor([-0.5888])\n",
      "tensor([-0.5226])\n",
      "tensor([0.3329])\n",
      "tensor([0.2991])\n",
      "tensor([-0.2754])\n",
      "tensor([-0.3052])\n",
      "tensor([0.6775])\n",
      "tensor([-0.4124])\n",
      "tensor([0.0058])\n",
      "tensor([-2.1046])\n",
      "tensor([1.1280])\n",
      "tensor([-0.0399])\n",
      "tensor([0.8230])\n",
      "tensor([1.2682])\n",
      "tensor([0.8757])\n",
      "tensor([0.2030])\n",
      "tensor([1.1730])\n",
      "tensor([0.8782])\n",
      "tensor([0.5656])\n",
      "tensor([-0.6416])\n",
      "tensor([-0.1171])\n",
      "tensor([0.6678])\n",
      "tensor([0.6161])\n",
      "tensor([0.8119])\n",
      "tensor([0.1731])\n",
      "tensor([0.6582])\n",
      "tensor([0.4964])\n",
      "tensor([0.9411])\n",
      "tensor([0.3260])\n",
      "tensor([-1.2779])\n",
      "tensor([-2.1862])\n",
      "tensor([1.2954])\n",
      "tensor([0.4755])\n",
      "tensor([0.6993])\n",
      "tensor([-0.9158])\n",
      "tensor([0.4301])\n",
      "tensor([0.1925])\n",
      "tensor([0.7934])\n",
      "tensor([1.4251])\n",
      "tensor([1.2307])\n",
      "tensor([0.6348])\n",
      "tensor([1.0193])\n",
      "tensor([1.2412])\n",
      "tensor([0.8429])\n",
      "tensor([-1.3055])\n",
      "tensor([0.0497])\n",
      "tensor([-0.5216])\n",
      "tensor([0.9870])\n",
      "tensor([0.1589])\n",
      "tensor([-0.9307])\n",
      "tensor([0.5056])\n",
      "tensor([1.0634])\n",
      "tensor([0.8902])\n",
      "tensor([0.3822])\n",
      "tensor([0.6221])\n",
      "tensor([0.4617])\n",
      "tensor([1.3751])\n",
      "tensor([-0.9324])\n",
      "tensor([1.0646])\n",
      "tensor([0.5339])\n",
      "tensor([-2.7540])\n",
      "tensor([0.5564])\n",
      "tensor([0.0332])\n",
      "tensor([0.0445])\n",
      "tensor([0.6436])\n",
      "tensor([0.7319])\n",
      "tensor([0.6240])\n",
      "tensor([0.1747])\n",
      "tensor([0.6306])\n",
      "tensor([-0.1177])\n",
      "tensor([0.6344])\n",
      "tensor([0.9778])\n",
      "tensor([0.9494])\n",
      "tensor([0.8636])\n",
      "tensor([-0.2226])\n",
      "tensor([0.8904])\n",
      "tensor([0.7721])\n",
      "tensor([0.6710])\n",
      "tensor([0.7390])\n",
      "tensor([0.7225])\n",
      "tensor([0.2756])\n",
      "tensor([0.6183])\n",
      "tensor([0.4895])\n",
      "tensor([0.5840])\n",
      "tensor([0.6803])\n",
      "tensor([0.3720])\n",
      "tensor([0.1759])\n",
      "tensor([-0.7436])\n",
      "tensor([0.7041])\n",
      "tensor([0.6684])\n",
      "tensor([0.8769])\n",
      "tensor([1.0240])\n",
      "tensor([-1.1059])\n",
      "tensor([0.6796])\n",
      "tensor([0.6670])\n",
      "tensor([-1.8865])\n",
      "tensor([0.4635])\n",
      "tensor([-2.9896])\n",
      "tensor([0.3540])\n",
      "tensor([0.6796])\n",
      "tensor([0.1896])\n",
      "tensor([-0.9948])\n",
      "tensor([0.1379])\n",
      "tensor([-0.4749])\n",
      "tensor([0.4142])\n",
      "tensor([0.1340])\n",
      "tensor([0.5385])\n",
      "tensor([-0.4324])\n",
      "tensor([0.2628])\n",
      "tensor([0.6325])\n",
      "tensor([-0.0674])\n",
      "tensor([0.3426])\n",
      "tensor([0.5836])\n",
      "tensor([0.5951])\n",
      "tensor([0.6896])\n",
      "tensor([0.7603])\n",
      "tensor([-0.5570])\n",
      "tensor([0.3996])\n",
      "tensor([0.5144])\n",
      "tensor([0.2727])\n",
      "tensor([0.2248])\n",
      "tensor([0.2605])\n",
      "tensor([0.3839])\n",
      "tensor([0.1295])\n",
      "tensor([0.4854])\n",
      "tensor([0.8100])\n",
      "tensor([0.5663])\n",
      "tensor([-0.2209])\n",
      "tensor([0.6335])\n",
      "tensor([0.7136])\n",
      "tensor([0.5569])\n",
      "tensor([0.0147])\n",
      "tensor([0.6485])\n",
      "tensor([0.5277])\n",
      "tensor([-0.1813])\n",
      "tensor([-1.2279])\n",
      "tensor([-0.9962])\n",
      "tensor([0.4521])\n",
      "tensor([0.7092])\n",
      "tensor([0.7709])\n",
      "tensor([0.7806])\n",
      "tensor([-0.4170])\n",
      "tensor([0.1643])\n",
      "tensor([0.0228])\n",
      "tensor([1.0059])\n",
      "tensor([-0.7716])\n",
      "tensor([0.7292])\n",
      "tensor([0.9513])\n",
      "tensor([0.7063])\n",
      "tensor([-1.3346])\n",
      "tensor([0.5387])\n",
      "tensor([0.7029])\n",
      "tensor([0.5795])\n",
      "tensor([0.3268])\n",
      "tensor([0.7295])\n",
      "tensor([-1.3202])\n",
      "tensor([0.3857])\n",
      "tensor([-0.1500])\n",
      "tensor([0.6264])\n",
      "tensor([1.0883])\n",
      "tensor([0.9298])\n",
      "tensor([0.8933])\n",
      "tensor([0.9064])\n",
      "tensor([0.2093])\n",
      "tensor([0.2859])\n",
      "tensor([0.6287])\n",
      "tensor([0.3184])\n",
      "tensor([0.2477])\n",
      "tensor([0.7396])\n",
      "tensor([-0.5455])\n",
      "tensor([-2.0219])\n",
      "tensor([-0.4591])\n",
      "tensor([1.1160])\n",
      "tensor([1.3384])\n",
      "tensor([0.6965])\n",
      "tensor([-1.4411])\n",
      "tensor([1.2735])\n",
      "tensor([1.1522])\n",
      "tensor([1.3204])\n",
      "tensor([-3.0311])\n",
      "tensor([0.3707])\n",
      "tensor([1.1048])\n",
      "tensor([0.6904])\n",
      "tensor([-0.0701])\n",
      "tensor([0.8646])\n",
      "tensor([0.0098])\n",
      "tensor([0.6690])\n",
      "tensor([-0.5036])\n",
      "tensor([0.2717])\n",
      "tensor([0.6438])\n",
      "tensor([0.8617])\n",
      "tensor([0.6198])\n",
      "tensor([-0.1743])\n",
      "tensor([1.2269])\n",
      "tensor([0.3595])\n",
      "tensor([0.6298])\n",
      "tensor([1.2110])\n",
      "tensor([1.0514])\n",
      "tensor([0.6341])\n",
      "tensor([1.0904])\n",
      "tensor([1.2070])\n",
      "tensor([0.6106])\n",
      "tensor([-0.6155])\n",
      "tensor([-2.1303])\n",
      "tensor([-0.0210])\n",
      "tensor([0.0806])\n",
      "tensor([0.5452])\n",
      "tensor([1.0413])\n",
      "tensor([0.9656])\n",
      "tensor([-0.3697])\n",
      "tensor([1.5830])\n",
      "tensor([1.7782])\n",
      "tensor([-0.2736])\n",
      "tensor([0.0600])\n",
      "tensor([1.0598])\n",
      "tensor([0.2034])\n",
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]], dtype=torch.int32)\n",
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter concentration (Tensor of shape (299, 2)) of distribution Dirichlet(concentration: torch.Size([299, 2])) to satisfy the constraint IndependentConstraint(GreaterThan(lower_bound=0.0), 1), but found invalid values:\ntensor([[nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan]], grad_fn=<StackBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[565], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m Config(use_critic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_gae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m df_ppo \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_parameters_ppo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_ppo\u001b[38;5;241m.\u001b[39mplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_frames\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmooth_reward\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[544], line 109\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(args, parameter_update, env_param, seed)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    108\u001b[0m     exps, logs1 \u001b[38;5;241m=\u001b[39m collect_experiences(env, acmodel, args, device)\n\u001b[0;32m--> 109\u001b[0m     logs2 \u001b[38;5;241m=\u001b[39m \u001b[43mparameter_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlogs1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlogs2}\n\u001b[1;32m    113\u001b[0m     num_frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_frames\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[562], line 75\u001b[0m, in \u001b[0;36mupdate_parameters_ppo\u001b[0;34m(optimizer, acmodel, sb, args)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mtrain_ac_iters):\n\u001b[1;32m     74\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 75\u001b[0m     loss_pi, approx_kl \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_policy_loss_ppo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_logp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madvantage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     loss_v \u001b[38;5;241m=\u001b[39m _compute_value_loss(sb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m], sb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscounted_reward\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     78\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_v \u001b[38;5;241m+\u001b[39m loss_pi\n",
      "Cell \u001b[0;32mIn[562], line 24\u001b[0m, in \u001b[0;36mupdate_parameters_ppo.<locals>._compute_policy_loss_ppo\u001b[0;34m(obs, old_logp, actions, advantages)\u001b[0m\n\u001b[1;32m     22\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs)\n\u001b[1;32m     23\u001b[0m eps \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mclip_ratio\n\u001b[0;32m---> 24\u001b[0m thrust_dist, rudder_dist, _ \u001b[38;5;241m=\u001b[39m \u001b[43macmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(actions)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#print(thrust_dist.log_prob(actions[:,0]))\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[515], line 27\u001b[0m, in \u001b[0;36mACModel.forward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Thrust\u001b[39;00m\n\u001b[1;32m     26\u001b[0m thrust_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_thrust(x))  \u001b[38;5;66;03m# Ensure parameters are positive\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m thrust_dist \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBeta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthrust_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrust_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adding 1 to avoid 0\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Rudder\u001b[39;00m\n\u001b[1;32m     29\u001b[0m rudder_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_rudder(x))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/distributions/beta.py:48\u001b[0m, in \u001b[0;36mBeta.__init__\u001b[0;34m(self, concentration1, concentration0, validate_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m     concentration1, concentration0 \u001b[38;5;241m=\u001b[39m broadcast_all(\n\u001b[1;32m     43\u001b[0m         concentration1, concentration0\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     concentration1_concentration0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m     46\u001b[0m         [concentration1, concentration0], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dirichlet \u001b[38;5;241m=\u001b[39m \u001b[43mDirichlet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcentration1_concentration0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dirichlet\u001b[38;5;241m.\u001b[39m_batch_shape, validate_args\u001b[38;5;241m=\u001b[39mvalidate_args)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/distributions/dirichlet.py:59\u001b[0m, in \u001b[0;36mDirichlet.__init__\u001b[0;34m(self, concentration, validate_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcentration \u001b[38;5;241m=\u001b[39m concentration\n\u001b[1;32m     58\u001b[0m batch_shape, event_shape \u001b[38;5;241m=\u001b[39m concentration\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], concentration\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/distributions/distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter concentration (Tensor of shape (299, 2)) of distribution Dirichlet(concentration: torch.Size([299, 2])) to satisfy the constraint IndependentConstraint(GreaterThan(lower_bound=0.0), 1), but found invalid values:\ntensor([[nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan],\n        [nan, nan]], grad_fn=<StackBackward0>)"
     ]
    }
   ],
   "source": [
    "args = Config(use_critic=True, use_gae=True)\n",
    "df_ppo = run_experiment(args, update_parameters_ppo, env_param)\n",
    "df_ppo.plot(x='num_frames', y=['reward', 'smooth_reward'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
